# -*- coding: utf-8 -*-
"""
Created on Tue Mar 13 19:54:39 2018

@author: faraz
"""

import re
import requests
from bs4 import BeautifulSoup

class Aarz:
    location = ""
    price_min = 0
    price_max = 0
    purpose = 0
    page = 1
    
    def __init__(self, location = 'samanabad',
                 price_min = 0,
                 price_max = 0,
                 purpose = 0,
                 page = 1):
        """Constructor
        
        Keyword arguments:
            location -- Listings of the location will be parsed.
                Note: Use location name instead of link i.e. 'key' in dictionary generated by 'pyAraz.Locations'.
            price_min -- This argument will determine lower limit of price.
            price_max -- This argument will determine upper limit of price.
            purpose -- This will determine weather to parse '0: Buy/Sell' or '1: Rentals'.
            page -- This will determine which page to parse for a particular area.
        """
        self.location = location
        self.price_min = price_min
        self.price_max = price_max
        self.purpose = purpose # Buy is 0, rent is 1.
        self.page = page

    def getLink(self):
        location_link = "https://www.aarz.pk/search/page/" + str(self.page) + "?city_s=Lahore"
        
        loc_lp = "&loc1="
        price_min_lp = "&price_min="
        price_max_lp = "&price_max="
        purpose_lp = "&purpose="
        
        location_link += (loc_lp + self.location)
        
        if self.price_min > 0:
            location_link += (price_min_lp + str(self.price_min))
        
        if self.price_max > 0:
            location_link += (price_max_lp + str(self.price_max))
            
        if self.purpose == 0:
            location_link += purpose_lp + "Sell"
        else:
            location_link += purpose_lp + "Rent"
            
        return location_link
    
    def getHtmlDoc(self):
            return requests.get(self.getLink()).text
    
    def getSoup(self):
        return BeautifulSoup(self.getHtmlDoc(), 'lxml')
    
    def getListings(self):
        """This method will return parsed data of the desired area.
        
        In case the page doesn't contain any data, the method will return following:
            self.page -- Number of the page parse.
            0 -- In place of total_pages.
            None -- In place of listings dictionary.
            
        In case there is only one page in total, the method will return following:
            1 -- Number of the page parse.
            1 -- In place of total_pages.
            listings -- listings dictionary.
        
        The method returns following data:
            current_page -- Page which was parsed.
            total_pages -- Total number of pages that were parsed.
            listings -- Dictionary in following format:
                Key: Data index assigned by 'zameen.com' to the listing.
                Value: Another dictionary containing parsed data with following keys:
                    link -- Link to listing on 'zameen.com'.
                    title -- Title of the listing.
                    price -- Price/Rent of the property.
                    area -- Area of the property.
                    address -- Address of the property.
                    beds -- Number of beds (can be none)
                    baths -- Number of beds (can be none)
                    description -- Description of the listing.
                    addedOn -- Date on which the listing was created and updated.
        """
        listings = {}
        
        soup = self.getSoup()
        
        try:
            item_count = int(soup.find('div', attrs={'class': 'show_items'}).p.text.split(" ")[3])
        except AttributeError:
            return self.page, 0, None
        
        for listing in soup.findAll('div', attrs={'class': 'property-listing row'}):
            single = {}
            
            single['link'] = "https://www.aarz.pk" + listing.h2.a['href']
            single['title'] = listing.h2.a.text
            single['price'] = listing.h2.h4.text
            
            regex_compiled = re.compile(r"\d*\s(Kanal|Marla)", re.I)
            
            match = regex_compiled.search(single['title'])
            
            if match is not None:
                single['area'] = match.group(0)
            else:
                single['area'] = None
            
            info_div = listing.find('div', attrs={'class': 'col-md-5 col-sm-4 col-xs-12'})
            
            single['address'] = info_div.h4.a.text
            
            bedsnbath = info_div.find('div', attrs={'class': 'property-features'}).text.strip().split(" ")
            
            single['beds'] = int(bedsnbath[1].strip())
            single['bath'] = int(bedsnbath[-1])
            
            try:
                single['description'] = info_div.find('div', attrs={'class': 'text-muted property-desc'}).p.text.strip()
            except AttributeError:
                try:
                    single['description'] = info_div.find('div', attrs={'class': 'text-muted property-desc'}).p.text.strip()
                except AttributeError:
                    single['description'] = None
            
            added_info = info_div.find('div', attrs={'class': 'text-muted property-side-info'}).text.strip().split(" ")
            
            single['addedOn'] = added_info[0] + " " + added_info[1] + " " + added_info[2]
#            single['addedBy'] = added_info[-2].split("\n")[0] + " " + added_info[-2].split("\n")[1] + " " + added_info[-1] 
            
            listings[item_count] = single
            item_count += 1
            
        try:
            page_info = soup.find('p', attrs={'class': 'text-muted text-center'}).text
        except AttributeError:
            return 1, 1, listings
        
        current_page = int(page_info.strip().split(" ")[1])
        total_pages = int(page_info.strip().split(" ")[-1])
            
        return current_page, total_pages, listings